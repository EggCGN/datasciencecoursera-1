---
title: "Week 1 assignment"
output: html_notebook
---

# Memo

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

# Week 1 course notes

Slides are available [here](https://github.com/rdpeng/courses/tree/master/03_GettingData).
Rprogramming uselful book is available here : https://bookdown.org/rdpeng/rprogdatascience/

## data.table

```{r}
library(data.table)
dt = data.table(x=rnorm(9), y=rep(c("a","b","c"), each=3), z=rnorm(9))
df = data.frame(x=rnorm(9), y=rep(c("a","b","c"), each=3), z=rnorm(9))
head(dt)
```
Subsetting works like data.frame, but when you index with a single index it will subset by rows while it is by columns with data.frame.

```{r}
dt[c(2,3)]
df[c(2,3)]
```

You should use a comma to get the same result as data.frame.

```{r}
dt[,c(2,3)]
df[,c(2,3)]
```

Calculate values for variables with expressions:

```{r}
dt[,list(mean(x), sum(z))]
```

Adding new columns:

```{r}
dt[,w:=z^2]
head(dt)
```

*Warning*: pay attention to copy assignment. Doing `dt2 <- dt` will not create a copy of dt. Modifying one of these two variables will modify the other one.

Special variables: .N An integer, length 1, containing the number of elements of a factor level

```{r}
set.seed(123);
DT <- data.table(x=sample(letters[1:3], 1E5, TRUE))
DT[, .N, by=x]
```

# Week 1 quiz

### Question 1

The American Community Survey distributes downloadable data about United States communities. Download the 2006 microdata survey about housing for the state of Idaho using download.file() from here:

https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv

and load the data into R. The code book, describing the variable names is here:

https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf

How many properties are worth $1,000,000 or more?

```{r}
link <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
file_path <- "/tmp/housing_Idaho.csv"
download.file(link, file_path)
print(date())
```
```{r}
library(data.table)
dt <- fread(file_path)
dt[, .N, VAL >= 24]
```

Answer: there are 53 properties above $1,000,000.

### Question 2

Use the data you loaded from Question 1. Consider the variable FES in the code book. Which of the "tidy data" principles does this variable violate?

Answer: tidy data has one variable per column

### Question 3

Download the Excel spreadsheet on Natural Gas Aquisition Program here:
https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx
Read rows 18-23 and columns 7-15 into R and assign the result to a variable called: dat

What is the value of: sum(dat$Zip*dat$Ext,na.rm=T)

```{r}
link <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
file_path <- "/tmp/gov_NGPA.xlsx"
download.file(link, file_path)
print(date())
```

```{r}
library(xlsx)
dat <- read.xlsx(file_path, sheetIndex=1, colIndex=7:15, rowIndex=18:23)
sum(dat$Zip*dat$Ext,na.rm=T)
```

Answer: 36534720

### Question 4

Read the XML data on Baltimore restaurants from here:

https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml

How many restaurants have zipcode 21231?

```{r}
library(XML)
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileURL, useInternal=TRUE)
rootNode <- xmlRoot(doc)
print(date())
```

```{r}
length(xpathSApply(rootNode, "//raw[@zipcode=21231]", xmlValue))
```

This question has not been tested due to sml lib limitation on the current computer.

### Question 5

The American Community Survey distributes downloadable data about United States communities. Download the 2006 microdata survey about housing for the state of Idaho using download.file() from here:

https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv

using the fread() command load the data into an R object named "DT"

The following are ways to calculate the average value of the variable "pwgt15" broken down by sex. Using the data.table package, which will deliver the fastest user time?

```{r}
link <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
file_path <- "/tmp/housing_Idaho.csv"
download.file(link, file_path)
print(date())
```

```{r}
library(data.table)
DT <- fread(file_path)
system.time(tapply(DT$pwgtp15, DT$SEX, mean))
Sys.sleep(0.5)
system.time(sapply(split(DT$pwgtp15, DT$SEX), mean))
Sys.sleep(0.5)
system.time(DT[,mean(pwgtp15), by=SEX])
Sys.sleep(0.5)
system.time(mean(DT$pwgtp15, by=DT$SEX))
```

The answer is *DT[,mean(pwgtp15), by=SEX]* as said in the course, but during the above test, we can see that this is the longest.

# Week 2 course notes

## Reading from HDF5

```{r}
library(rhdf5)
filename = "example.h5"
created = h5createFile(filename)
created
```

```{r}
created = h5createGroup(filename, "foo")
A = matrix(1:10, nr=5, nc=2)
h5write(A, filename, "foo/A")
readA = h5read(filename, "foo/A")
print(readA)
```

## Reading from the Web

```{r}
con = url("https://www.data.gouv.fr/fr/datasets/demandes-de-valeurs-foncieres/")
htmlCode = readLines(con)
close(con)
head(htmlCode)
```
The XML package is needed to parse the output.

Another way is to use the library httr and GET:

```{r}
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
library(httr)
parsedHtml = httr::parse_url(url)
xpathSApply(parsedHtml, "//title", xmlValue)
```

## API

```{r}
myapp = oauth_app("twitter",
                  key = "mykey", secret = "mysecret")
sig = sign_oauth1.0(myapp, token = "mytoken", token_secret = "token-secret")
homeTL = GET("http://yolo", sig)
# Use jsonlite::fromJSON to read json 
```

# Week 2 quiz

### Question 1

```{r}
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")

# 2. To make your own application, register at
#    https://github.com/settings/developers. Use any URL for the homepage URL
#    (http://github.com is fine) and  http://localhost:1410 as the callback url
#
#    Replace your key and secret below.
myapp <- oauth_app("github",
  key = "4b273bafb6c31aca8616",
  secret = "434f708437af606c20f1de9e080b5127804b9b75"
)

# 3. Get OAuth credentials
github_token <- oauth1.0_token(oauth_endpoints("github"), myapp)

# 4. Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
raw_content <- content(req)
json_content <- jsonlite::fromJSON(jsonlite::toJSON(raw_content))
df <- as.data.frame(json_content)
date_created <- subset(df, name == "datasharing")["created_at"]
unlist(date_created)
```

### Question 2

The sqldf package allows for execution of SQL commands on R data frames. We will use the sqldf package to practice the queries we might send with the dbSendQuery command in RMySQL.

Download the American Community Survey data and load it into an R object called _acs_
https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv

Which of the following commands will select only the data for the probability weights pwgtp1 with ages less than 50?

```{r}
acs <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
head(acs, 1)
```

```{r}
library(sqldf)
sqldf("select pwgtp1 from acs where AGEP < 50")
```

### Question 3

Using the same data frame you created in the previous problem, what is the equivalent function to unique(acs$AGEP)

```{r}
unique(acs$AGEP)
sqldf("select distinct AGEP from acs")
```

### Question 4

How many characters are in the 10th, 20th, 30th and 100th lines of HTML from this page:
http://biostat.jhsph.edu/~jleek/contact.html

```{r}
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
for(i in c(10,20,30,100)){
  print(nchar(htmlCode[i]))
}
```

### Question 5

Read this data set into R and report the sum of the numbers in the fourth of the nine columns.
https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for
Original source of the data: http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for

```{r}
con = url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
htmlCode = readLines(con)
close(con)
head(htmlCode)
```
```{r}
nchar(htmlCode[5])
# total: 62
init_col = 16
blanc_size = 4
col_size = 3
substr(htmlCode[5],1,15)
substr(htmlCode[5],16,19)
substr(htmlCode[5],20,23)
substr(htmlCode[5],24,28) # blanc
substr(htmlCode[5],29,32)
substr(htmlCode[5],33,36)

x = c()
for(i in 5:length(htmlCode)){
  x = append(x, as.numeric(substr(htmlCode[i],29,32)))
}
sum(x)
```

# Week 3 course notes

See this [link](https://github.com/rdpeng/courses/blob/master/03_GettingData/03_01_subsettingAndSorting/index.md) to get example about subsetting dataframe.

#### Remember:
* `%in%` allows you to filter by value a data.frame or data.table
* `xtabs(Var_to_print ~ by_var1_col + by_var2_col)` allows you to get the count for the variable to print by different other variable. Use a flat table ot print if there are more han 2 variables: `ftable(xtabs(...))`

# Week 3 quiz

### Question 1
